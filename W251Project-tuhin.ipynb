{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berkeley MIDS W251 Final Project\n",
    "\n",
    "Developers: \n",
    "* [Dhaval Bhatt](https://github.com/dhavalbhatt)\n",
    "* [James Gray](https://github.com/jamesgray007)\n",
    "* [Tuhin Mahmud](https://github.com/tuhinmahmud)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Import third-party libraries\n",
    "import dask\n",
    "import dask.bag as db\n",
    "from boto.s3.connection import S3Connection # Python API to AWS; http://docs.pythonboto.org/en/latest/index.html\n",
    "from boto.s3.key import Key\n",
    "import bokeh # http://bokeh.pydata.org/en/latest/\n",
    "#import pyspark # https://spark.apache.org/docs/0.9.0/python-programming-guide.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "AWS_ACCESS = \"XXXXXXXXXXXXX\"\n",
    "AWS_SECRET = \"XXXXXXXXXXXXX\"\n",
    "REDDITS3 = \"blaze-data\" # Continuum Analytics S3 data; reddit in the reddit/json/RC_YYYY-MM.json\n",
    "REDDIT_MONTH_KEY = 'reddit/json/2007/RC_2007-11.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and Insights \n",
    "\n",
    "This project analyzes Redditt posts to answer the following questions:\n",
    "\n",
    "1. What is the month-over-month volume growth (trend) of subreddit \"r/datascience\" between 2007-2015?\n",
    "2. What are the top ten words for \"r/datascience\" for each year between 2007-2015?\n",
    "3. What is the sentiment about \"r/datascience\" for each year between 2007-2015?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technology\n",
    "\n",
    "This project explores the use of multiple technologies to process Big Data at scale using cloud platforms.  \n",
    "\n",
    "* Spark\n",
    "* Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download one month of Reddit data from Amazon S3\n",
    "\n",
    "Reddit JSON schema details (22 fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit.json file already downloaded\n"
     ]
    }
   ],
   "source": [
    "# use Boto to access S3\n",
    "import os\n",
    "if not os.path.exists(\"reddit.json\"):\n",
    "    S3conn = S3Connection(AWS_ACCESS, AWS_SECRET)\n",
    "    mybucket = S3conn.get_bucket(REDDITS3)\n",
    "    for key in mybucket.list():\n",
    "        #print key.name.encode('utf-8')\n",
    "        if key.key == REDDIT_MONTH_KEY:  # get one month of data\n",
    "            key.get_contents_to_filename(\"reddit.json\")\n",
    "            print \"downloaded json\"\n",
    "else:\n",
    "    print \"reddit.json file already downloaded\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computations Using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load JSON file into dask bag\n",
    "#data = db.from_filenames(\"reddit.json\", chunkbytes=100000).map(json.loads)\n",
    "data = db.from_filenames(\"reddit.json\").map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'archived': True,\n",
       "  u'author': u'BraveSirRobin',\n",
       "  u'author_flair_css_class': None,\n",
       "  u'author_flair_text': None,\n",
       "  u'body': u'Some of the linux distros, as well as BSD, make this really easy. You don\\'t need to tweak anything, it\\'s \"ready to compile\". I don\\'t bother with it myself.',\n",
       "  u'controversiality': 0,\n",
       "  u'created_utc': u'1193875218',\n",
       "  u'distinguished': None,\n",
       "  u'downs': 0,\n",
       "  u'edited': False,\n",
       "  u'gilded': 0,\n",
       "  u'id': u'c02chew',\n",
       "  u'link_id': u't3_5zjl1',\n",
       "  u'name': u't1_c02chew',\n",
       "  u'parent_id': u't1_c02ch4f',\n",
       "  u'retrieved_on': 1427424835,\n",
       "  u'score': 2,\n",
       "  u'score_hidden': False,\n",
       "  u'subreddit': u'reddit.com',\n",
       "  u'subreddit_id': u't5_6',\n",
       "  u'ups': 2},)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly posts: 372983\n",
      "Computation time: 10.0100028515 second\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print \"Monthly posts: \" + str(data.count().compute())\n",
    "end = time.time()\n",
    "executionTime = end - start\n",
    "print \"Computation time: \" + str(executionTime) + \" second\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag.core.Bag"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AlchemyApi for sentiment analysis of the reddit comments\n",
    "http://www.alchemyapi.com/developers/getting-started-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.10 :: Anaconda 2.5.0 (x86_64)\n",
      "Key: 892322060e70b741767ac916896aeae6d507293b was written to api_key.txt\n",
      "You are now ready to start using AlchemyAPI. For an example, run: python example.py\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "#prepare using alchemy api for sentiment analysis\n",
    "!python /Users/tuhinm/berkeley/alchemyapi_python/alchemyapi.py 892322060e70b741767ac916896aeae6d507293b\n",
    "\n",
    "sys.path.insert(1,'/Users/tuhinm/berkeley/alchemyapi_python')\n",
    "# Create the AlchemyAPI Object\n",
    "\n",
    "from alchemyapi import AlchemyAPI\n",
    "import json\n",
    "alchemyapi = AlchemyAPI()\n",
    "def sentimentAnalysis(mytext,target):\n",
    "    response = alchemyapi.sentiment_targeted('text',mytext, target)\n",
    "    if response['status'] == 'OK':\n",
    "        #print('## Response Object ##')\n",
    "        #print(json.dumps(response, indent=4))\n",
    "        #print('')\n",
    "        #print('## Targeted Sentiment ##')\n",
    "        type=response['docSentiment']['type']\n",
    "        score=None\n",
    "        if 'score' in response['docSentiment']:\n",
    "            score=response['docSentiment']['score']\n",
    "        return (type,score)\n",
    "    else:\n",
    "        print('Error in targeted sentiment analysis call: ',\n",
    "              response['statusInfo'])\n",
    "    return None\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Some of the linux distros, as well as BSD, make this really easy. You don't need to tweak anything, it's \"ready to compile\". I don't bother with it myself.\n",
      "###################################################\n",
      "Sentiment for word:  linux  on review#:0 is:(u'neutral', None)\n",
      "###################################################\n",
      "1383 &gt; That seemed to show an awareness of open source, and of its importance for the future of computing, that was surprising coming from such high-level – and usually tech-averse – politicians.\n",
      "\n",
      "You should have started worrying at this point.\n",
      "\n",
      "There's a dystopic internet future, here: today's young generation of Europe will grow up to take on the mantle of hyperstatist, central-planning governance -- and won't have the humility of this generation's leadership when it comes to technical matters.  \"Oh,\" this raised-on-Windows, totally-coded-a-webpage-this-one-time generation will say, \"open source?  Whatever, man-- linux had shitty games.\"\n",
      "###################################################\n",
      "Sentiment for word:  linux  on review#:1383 is:(u'negative', u'-0.631043')\n",
      "###################################################\n"
     ]
    }
   ],
   "source": [
    "#subreddit = data.filter(lambda x: x['subreddit'] == 'movies')\n",
    "reviews= data\n",
    "findstr=' linux '\n",
    "for i,review in enumerate(reviews):\n",
    "    reviewBody=review['body']\n",
    "    if not findstr in reviewBody:\n",
    "        continue\n",
    "    print i,reviewBody\n",
    "    print \"###################################################\"\n",
    "    sentiment=sentimentAnalysis(reviewBody,findstr)\n",
    "    print \"Sentiment for word: %s on review#:%d is:%s\" % (findstr,i,sentiment)\n",
    "    print \"###################################################\"\n",
    "    if i > 100:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
